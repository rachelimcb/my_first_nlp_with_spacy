{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.', 'When', 'learning', 'data', 'science', ',', 'you', 'should', \"n't\", 'get', 'discouraged', '!', '\\n', 'Challenges', 'and', 'setbacks', 'are', \"n't\", 'failures', ',', 'they', 'are', 'just', 'part', 'of', 'the', 'journey', '.', 'You', \"'ve\", 'got', 'this', '!']\n",
      "['This is a sentence.', \"When learning data science, you shouldn't get discouraged!\", \"\\nChallenges and setbacks aren't failures, they are just part of the journey.\", \"You've got this!\"]\n",
      "Number of stop words: 326\n",
      "First 10 stop words: ['at', 'nine', 'â€™ll', 'are', 'how', 'otherwise', 'unless', 'only', \"'ll\", 'upon', 'yet', \"'d\", 'take', 'further', 'full', 'ourselves', 'see', 'thru', 'thereby', 'more']\n",
      "Filtered sentence is: [sentence, ., learning, data, science, ,, discouraged, !, \n",
      ", Challenges, setbacks, failures, ,, journey, ., got, !]\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en\n",
    "#!python -m pip install --upgrade pip\n",
    "import spacy\n",
    "text = \"\"\"This is a sentence. When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they are just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "doc = nlp(text)\n",
    "\n",
    "token_list = []\n",
    "for token in doc:\n",
    "    token_list.append(token.text)\n",
    "print(token_list)\n",
    "\n",
    "nlp=English()\n",
    "sbd = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sbd)\n",
    "doc = nlp(text)\n",
    "\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "print(sents_list)\n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "print('First 10 stop words: %s' % list(spacy_stopwords)[:20])\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "filtered_sent = []\n",
    "\n",
    "for word in doc:\n",
    "    if word.is_stop == False:\n",
    "        filtered_sent.append(word)\n",
    "print(\"Filtered sentence is: %s\" % filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This DET\n",
      "is VERB\n",
      "a DET\n",
      "sentence NOUN\n",
      ". PUNCT\n",
      "When ADV\n",
      "learning VERB\n",
      "data NOUN\n",
      "science NOUN\n",
      ", PUNCT\n",
      "you PRON\n",
      "should AUX\n",
      "n't ADV\n",
      "get VERB\n",
      "discouraged VERB\n",
      "! PUNCT\n",
      "\n",
      " SPACE\n",
      "Challenges NOUN\n",
      "and CCONJ\n",
      "setbacks NOUN\n",
      "are VERB\n",
      "n't ADV\n",
      "failures NOUN\n",
      ", PUNCT\n",
      "they PRON\n",
      "are VERB\n",
      "just ADV\n",
      "part NOUN\n",
      "of ADP\n",
      "the DET\n",
      "journey NOUN\n",
      ". PUNCT\n",
      "You PRON\n",
      "'ve VERB\n",
      "got VERB\n",
      "this DET\n",
      "! PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "#for token in doc:\n",
    "    #print(token.text,token.lemma_)\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "for word in nlp(text):\n",
    "    print(word.text,word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
